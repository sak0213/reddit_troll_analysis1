{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = \"https://api.pushshift.io/reddit/search/submission\"\n",
    "subreddit = \"conservative\"\n",
    "after_time = 1643691600\n",
    "final_time = 1647316800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date(created):\n",
    "    return dt.datetime.fromtimestamp(created)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_dict = {\n",
    "    \"title\":[],\n",
    "    \"score\":[],\n",
    "    \"id\":[], \n",
    "    \"url\":[],\n",
    "    \"comms_num\": [],\n",
    "    \"created\": [],\n",
    "    \"author\":[],\n",
    "    \"author_flair_text\":[],\n",
    "    \"permalink\":[],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_request = requests.get(f'{api}?subreddit={subreddit}&after={after_time}&size=100')\n",
    "initial_resp = initial_request.json()\n",
    "initial_results = initial_resp[\"data\"]\n",
    "for i in initial_results:\n",
    "    posts_dict['title'].append(i['title'])\n",
    "    posts_dict['score'].append(i['score'])\n",
    "    posts_dict['id'].append(i['id'])\n",
    "    posts_dict['url'].append(i['url'])\n",
    "    posts_dict['comms_num'].append(i['num_comments'])\n",
    "    posts_dict['created'].append(i['created_utc'])\n",
    "    posts_dict['author'].append(i['author'])\n",
    "    posts_dict['author_flair_text'].append(i['author_flair_text'])\n",
    "    posts_dict['permalink'].append(i['permalink'])\n",
    "df_main = pd.DataFrame(posts_dict).sort_values(by=['created'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = df_main['created'].max()\n",
    "printcount = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while counter < final_time:\n",
    "    try:\n",
    "        request = requests.get(f'{api}?subreddit={subreddit}&after={counter}&size=100')\n",
    "        response = request.json()\n",
    "        result = response[\"data\"]\n",
    "        posts_dict = {\n",
    "            \"title\":[],\n",
    "            \"score\":[],\n",
    "            \"id\":[], \n",
    "            \"url\":[],\n",
    "            \"comms_num\": [],\n",
    "            \"created\": [],\n",
    "            \"author\":[],\n",
    "            \"author_flair_text\":[],\n",
    "            \"permalink\":[],\n",
    "        }\n",
    "        for i in result:\n",
    "            posts_dict['title'].append(i['title'])\n",
    "            posts_dict['score'].append(i['score'])\n",
    "            posts_dict['id'].append(i['id'])\n",
    "            posts_dict['url'].append(i['url'])\n",
    "            posts_dict['comms_num'].append(i['num_comments'])\n",
    "            posts_dict['created'].append(i['created_utc'])\n",
    "            posts_dict['author'].append(i['author'])\n",
    "            posts_dict['author_flair_text'].append(i['author_flair_text'])\n",
    "            posts_dict['permalink'].append(i['permalink'])\n",
    "        df = pd.DataFrame(posts_dict).sort_values(by=['created'], ascending=False)\n",
    "        counter = df['created'].max()\n",
    "        df_main = df_main.append(df)\n",
    "        printcount += 1\n",
    "        print(f'Success: {printcount} requests made. Lenth of df_main: {len(df_main)} - date={get_date(counter)}')\n",
    "    except:\n",
    "        print(f'ERROR at {printcount} requests made. Lenth of df_main: {len(df_main)} - date={get_date(counter)} ---- {counter}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date(created):\n",
    "    return dt.datetime.fromtimestamp(created)\n",
    "_timestamp = df_main[\"created\"].apply(get_date)\n",
    "df_main = df_main.assign(timestamp=_timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_main.to_csv('conservative_posts.csv')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3b32922ae442944bae51de5c420d7545d4126864cdc0e7cb358b7d9924f39d3e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 ('PythonData')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
