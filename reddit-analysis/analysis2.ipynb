{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import nltk as nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "from collections import defaultdict\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from collections import Counter\n",
    "from _keys import db_user, db_password, db_name, db_host, db_port\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\steve\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stop=set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "select all_events.subreddit, all_events.submission, all_events.submission_type\n",
    "from\n",
    "\t(select *\n",
    "\tfrom (\n",
    "\tselect author, title as submission, created_utm as time_created, subreddit, 'post' as submission_type\n",
    "\tfrom sus_user_posts\n",
    "\twhere title !='This account is banned and is temporarily preserved for purposes of transparency.') as posts_aggregate\n",
    "\tunion\n",
    "\tselect *\n",
    "\tfrom (\n",
    "\tselect author, comment_body as submission, created_utc as time_created, subreddit, 'comment' as submission_type\n",
    "\tfrom sus_user_comments) as comments_aggregate) as all_events\n",
    "where length(submission) > 0 and subreddit not in ('funny', 'aww') and submission_type = 'post'\n",
    "\"\"\"\n",
    "conn = psycopg2.connect(dbname=db_name, user=db_user, password=db_password, host=db_host, port=db_port)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql(sql, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_top_ngrams(text, n=3):\n",
    "    stop=set(stopwords.words('english'))\n",
    "\n",
    "    new= text.str.split()\n",
    "    new=new.values.tolist()\n",
    "    corpus=[word for i in new for word in i]\n",
    "\n",
    "    def _get_top_ngram(corpus, n=None):\n",
    "        vec = CountVectorizer(ngram_range=(n, n)).fit(corpus)\n",
    "        bag_of_words = vec.transform(corpus)\n",
    "        sum_words = bag_of_words.sum(axis=0) \n",
    "        words_freq = [(word, sum_words[0, idx]) \n",
    "                      for word, idx in vec.vocabulary_.items()]\n",
    "        words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "        return words_freq[:10]\n",
    "\n",
    "    top_n_bigrams=_get_top_ngram(text,n)[:50]\n",
    "    x,y=map(list,zip(*top_n_bigrams))\n",
    "    return list(zip(x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngram</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>black lives matter</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>year old boy</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what do you</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>in the us</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>do you think</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>year old girl</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>in front of</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>shot by police</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>12 year old</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>one of the</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                ngram  count\n",
       "0  black lives matter     34\n",
       "1        year old boy     24\n",
       "2         what do you     23\n",
       "3           in the us     21\n",
       "4        do you think     20\n",
       "5       year old girl     19\n",
       "6         in front of     19\n",
       "7      shot by police     18\n",
       "8         12 year old     17\n",
       "9          one of the     16"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_df = pd.DataFrame(generate_top_ngrams(df['submission']), columns=['ngram','count'])\n",
    "nlp_df.head(15)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3b32922ae442944bae51de5c420d7545d4126864cdc0e7cb358b7d9924f39d3e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 ('PythonData')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
